{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 564 4438 22111 48075\n",
      "35 510 4306 20177 46468\n",
      "65 951 543 159 1\n",
      "65 794 350 129 2\n"
     ]
    }
   ],
   "source": [
    "# Need to create a data structure allowing for easy lookup of common word overlaps\n",
    "# First, how big is this this going to be?\n",
    "\n",
    "from nltk.corpus import cmudict\n",
    "from collections import Counter\n",
    "\n",
    "d = cmudict.dict()\n",
    "\n",
    "def n_head_graphs(k):\n",
    "    return len(set([g[:k] for g in d.iterkeys() if len(g) >= k]))\n",
    "\n",
    "def n_tail_graphs(k):\n",
    "    return len(set([g[-k:] for g in d.iterkeys() if len(g) >= k]))\n",
    "\n",
    "def n_head_phones(k):\n",
    "    return len(set([tuple(p[0][:k]) for p in d.itervalues() if len(p) >= k]))\n",
    "\n",
    "def n_tail_phones(k):\n",
    "    return len(set([tuple(p[0][-k:]) for p in d.itervalues() if len(p) >= k]))\n",
    "                   \n",
    "print n_head_graphs(1), n_head_graphs(2), n_head_graphs(3), n_head_graphs(4), n_head_graphs(5)\n",
    "print n_tail_graphs(1), n_tail_graphs(2), n_tail_graphs(3), n_tail_graphs(4), n_tail_graphs(5)\n",
    "print n_head_phones(1), n_head_phones(2), n_head_phones(3), n_head_phones(4), n_head_phones(5)\n",
    "print n_tail_phones(1), n_tail_phones(2), n_tail_phones(3), n_tail_phones(4), n_tail_phones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need each of the following:\n",
    "# 1) subgrapheme head frequency\n",
    "# 2) subgrapheme tail frequency\n",
    "# 3) (subgrapheme,subphoneme) head frequency\n",
    "# 4) (subgrapheme,subphoneme) tail frequency\n",
    "# 5) (subgrapheme,subphoneme) overall frequency\n",
    "\n",
    "# This requires loading in alignments\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../code')\n",
    "\n",
    "from word import Word\n",
    "from pronunciation_dictionary import PronunciationDictionary\n",
    "from sequence_alignment import SequenceAlignment\n",
    "\n",
    "pd = PronunciationDictionary.load('../data/pronunciation_dictionary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a',), ('l', 'l'), ('i',), ('g',), ('a',), ('t',), ('o', 'r')]\n",
      "[(u'AE1',), (u'L',), (u'AH0',), (u'G',), (u'EY2',), (u'T',), (u'ER0',)]\n"
     ]
    }
   ],
   "source": [
    "print pd.grapheme_to_word_dict['alligator'].grapheme_to_arpabet_phoneme_alignment.seq1\n",
    "print pd.grapheme_to_word_dict['alligator'].grapheme_to_arpabet_phoneme_alignment.seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_chunks_to_key(g):\n",
    "    return ''.join(sum(map(list, g), []))\n",
    "\n",
    "def phone_chunks_to_key(p):\n",
    "    return tuple(sum(map(list, p), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# smooth by using default value of 1 to avoid singularities when length > 5\n",
    "# fine... what if I use a Counter instead?\n",
    "\n",
    "subgrapheme_head_counts = defaultdict(lambda: 1)\n",
    "subgrapheme_tail_counts = defaultdict(lambda: 1)\n",
    "subgrapheme_counts = defaultdict(lambda: 1)\n",
    "\n",
    "subphoneme_head_counts = defaultdict(lambda: 1)\n",
    "subphoneme_tail_counts = defaultdict(lambda: 1)\n",
    "subphoneme_counts = defaultdict(lambda: 1)\n",
    "\n",
    "subword_head_counts = defaultdict(lambda: 1)\n",
    "subword_tail_counts = defaultdict(lambda: 1)\n",
    "subword_counts = defaultdict(lambda: 1)\n",
    "\n",
    "vocab_size = 0\n",
    "\n",
    "for grapheme,word in pd.grapheme_to_word_dict.iteritems():\n",
    "    graph_chunks = word.grapheme_to_arpabet_phoneme_alignment.seq1\n",
    "    phone_chunks = word.grapheme_to_arpabet_phoneme_alignment.seq2\n",
    "    vocab_size += 1\n",
    "    for k in range(1,6):\n",
    "        for i in range(len(graph_chunks)-k+1):\n",
    "            g = graph_chunks_to_key(graph_chunks[i:i+k])\n",
    "            p = phone_chunks_to_key(phone_chunks[i:i+k])\n",
    "            subgrapheme_counts[g] += 1\n",
    "            subphoneme_counts[p] += 1\n",
    "            subword_counts[(g,p)] += 1\n",
    "            if i == 0: # head\n",
    "                subgrapheme_head_counts[g] += 1\n",
    "                subphoneme_head_counts[p] += 1\n",
    "                subword_head_counts[(g,p)] += 1\n",
    "            if i + k == len(graph_chunks): # tail\n",
    "                subgrapheme_tail_counts[g] += 1\n",
    "                subphoneme_tail_counts[p] += 1\n",
    "                subword_tail_counts[(g,p)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new class 'SubwordFrequencies'\n",
    "\n",
    "from subword_frequency import SubwordFrequency\n",
    "\n",
    "sf = SubwordFrequency(\n",
    "        subgrapheme_head_counts, \n",
    "        subgrapheme_tail_counts, \n",
    "        subgrapheme_counts, \n",
    "        subphoneme_head_counts, \n",
    "        subphoneme_tail_counts, \n",
    "        subphoneme_counts, \n",
    "        subword_head_counts, \n",
    "        subword_tail_counts, \n",
    "        subword_counts,\n",
    "        vocab_size)\n",
    "sf.save('../data/subword_frequency.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print sf.get_subgrapheme_frequency('ammy', side='tail')\n",
    "print subgrapheme_tail_counts['ammy']\n",
    "print len([g for g in d.iterkeys() if g[-4:] == 'ammy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "x = ('gat',(u'G',u'EY2',u'T'))\n",
    "print sf.get_subword_frequency(*x, side='head')\n",
    "print sf.get_subword_frequency(*x, side='tail')\n",
    "print sf.get_subword_frequency(*x, side='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('h',), ('o',), ('l',), ('g',), ('a',), ('t',), ('e',)]\n",
      "[(u'HH',), (u'OW1',), (u'L',), (u'G',), (u'EY2',), (u'T',), ()]\n"
     ]
    }
   ],
   "source": [
    "print pd.grapheme_to_word_dict['holgate'].grapheme_to_arpabet_phoneme_alignment.seq1\n",
    "print pd.grapheme_to_word_dict['holgate'].grapheme_to_arpabet_phoneme_alignment.seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holgate\n",
      "(u'HH', u'OW1', u'L', u'G', u'EY2', u'T')\n",
      "\n",
      "castigating\n",
      "(u'K', u'AE1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "interrogators\n",
      "(u'IH2', u'N', u'T', u'EH1', u'R', u'AH0', u'G', u'EY2', u'T', u'ER0', u'Z')\n",
      "\n",
      "abrogating\n",
      "(u'AE1', u'B', u'R', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "obligate\n",
      "(u'AA1', u'B', u'L', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "obligates\n",
      "(u'AA1', u'B', u'L', u'AH0', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "obligated\n",
      "(u'AA1', u'B', u'L', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "delegates\n",
      "(u'D', u'EH1', u'L', u'AH0', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "delegated\n",
      "(u'D', u'EH1', u'L', u'AH0', u'G', u'EY2', u'T', u'AH0', u'D')\n",
      "\n",
      "investigating\n",
      "(u'IH0', u'N', u'V', u'EH1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "floodgates\n",
      "(u'F', u'L', u'AH1', u'D', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "litigator\n",
      "(u'L', u'IH1', u'T', u'AH0', u'G', u'EY2', u'T', u'ER0')\n",
      "\n",
      "irrigate\n",
      "(u'IH1', u'R', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "seagate\n",
      "(u'S', u'IY1', u'G', u'EY2', u'T')\n",
      "\n",
      "digate\n",
      "(u'D', u'AY1', u'G', u'EY2', u'T')\n",
      "\n",
      "corrugated\n",
      "(u'K', u'AO1', u'R', u'AH0', u'G', u'EY2', u'T', u'AH0', u'D')\n",
      "\n",
      "unmitigated\n",
      "(u'AH0', u'N', u'M', u'IH1', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "westgate\n",
      "(u'W', u'EH1', u'S', u'T', u'G', u'EY2', u'T')\n",
      "\n",
      "aggregated\n",
      "(u'AE1', u'G', u'R', u'AH0', u'G', u'EY2', u'T', u'AH0', u'D')\n",
      "\n",
      "bishopsgate\n",
      "(u'B', u'IH1', u'SH', u'AH0', u'P', u'S', u'G', u'EY2', u'T')\n",
      "\n",
      "instigators\n",
      "(u'IH1', u'N', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'ER0', u'Z')\n",
      "\n",
      "investigate\n",
      "(u'IH0', u'N', u'V', u'EH1', u'S', u'T', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "abrogate\n",
      "(u'AE1', u'B', u'R', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "mitigates\n",
      "(u'M', u'IH1', u'T', u'AH0', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "mitigated\n",
      "(u'M', u'IH1', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "castigate\n",
      "(u'K', u'AE1', u'S', u'T', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "alligator\n",
      "(u'AE1', u'L', u'AH0', u'G', u'EY2', u'T', u'ER0')\n",
      "\n",
      "delegating\n",
      "(u'D', u'EH1', u'L', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "profligate\n",
      "(u'P', u'R', u'AO1', u'F', u'L', u'IH0', u'G', u'EY2', u'T')\n",
      "\n",
      "alligators\n",
      "(u'AE1', u'L', u'AH0', u'G', u'EY2', u'T', u'ER0', u'Z')\n",
      "\n",
      "navigate\n",
      "(u'N', u'AE1', u'V', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "litigators\n",
      "(u'L', u'IH1', u'T', u'AH0', u'G', u'EY2', u'T', u'ER0', u'Z')\n",
      "\n",
      "tailgate\n",
      "(u'T', u'EY1', u'L', u'G', u'EY2', u'T')\n",
      "\n",
      "instigate\n",
      "(u'IH1', u'N', u'S', u'T', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "castigated\n",
      "(u'K', u'AE1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "koreagate\n",
      "(u'K', u'AO0', u'R', u'IY1', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "promulgating\n",
      "(u'P', u'R', u'AA1', u'M', u'AH0', u'L', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "filegate\n",
      "(u'F', u'AY1', u'L', u'G', u'EY2', u'T')\n",
      "\n",
      "desegregated\n",
      "(u'D', u'IH0', u'S', u'EH1', u'G', u'R', u'IH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "interrogate\n",
      "(u'IH0', u'N', u'T', u'EH1', u'R', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "delegate\n",
      "(u'D', u'EH1', u'L', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "instigates\n",
      "(u'IH1', u'N', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "investigated\n",
      "(u'IH0', u'N', u'V', u'EH1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'AH0', u'D')\n",
      "\n",
      "investigates\n",
      "(u'IH0', u'N', u'V', u'EH1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "floodgate\n",
      "(u'F', u'L', u'AH1', u'D', u'G', u'EY2', u'T')\n",
      "\n",
      "interrogating\n",
      "(u'IH0', u'N', u'T', u'EH1', u'R', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "segregate\n",
      "(u'S', u'EH1', u'G', u'R', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "navigators\n",
      "(u'N', u'AE1', u'V', u'AH0', u'G', u'EY2', u'T', u'ER0', u'Z')\n",
      "\n",
      "investigator\n",
      "(u'IH0', u'N', u'V', u'EH1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'ER0')\n",
      "\n",
      "newgateway\n",
      "(u'N', u'UW1', u'G', u'EY2', u'T', u'W', u'EY2')\n",
      "\n",
      "fumigate\n",
      "(u'F', u'Y', u'UW1', u'M', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "mitigating\n",
      "(u'M', u'IH1', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "mastergate\n",
      "(u'M', u'AE1', u'S', u'T', u'ER0', u'G', u'EY2', u'T')\n",
      "\n",
      "irrigator\n",
      "(u'IH1', u'R', u'AH0', u'G', u'EY2', u'T', u'ER0')\n",
      "\n",
      "obligating\n",
      "(u'AA1', u'B', u'L', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "desegregate\n",
      "(u'D', u'IH0', u'S', u'EH1', u'G', u'R', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "interrogator\n",
      "(u'IH2', u'N', u'T', u'EH1', u'R', u'AH0', u'G', u'EY2', u'T', u'ER0')\n",
      "\n",
      "segregating\n",
      "(u'S', u'EH1', u'G', u'R', u'IH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "investigative\n",
      "(u'IH0', u'N', u'V', u'EH1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'V')\n",
      "\n",
      "bathgate\n",
      "(u'B', u'AE1', u'TH', u'G', u'EY2', u'T')\n",
      "\n",
      "navigated\n",
      "(u'N', u'AE1', u'V', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "navigates\n",
      "(u'N', u'AE1', u'V', u'AH0', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "relegating\n",
      "(u'R', u'EH1', u'L', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "southgate\n",
      "(u'S', u'AW1', u'TH', u'G', u'EY2', u'T')\n",
      "\n",
      "congregate\n",
      "(u'K', u'AA1', u'NG', u'G', u'R', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "irrigated\n",
      "(u'IH1', u'R', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "instigated\n",
      "(u'IH1', u'N', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "interrogated\n",
      "(u'IH0', u'N', u'T', u'EH1', u'R', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "segregated\n",
      "(u'S', u'EH1', u'G', u'R', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "irangate\n",
      "(u'IH0', u'R', u'AA1', u'N', u'G', u'EY2', u'T')\n",
      "\n",
      "propagated\n",
      "(u'P', u'R', u'AA1', u'P', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "investigators\n",
      "(u'IH0', u'N', u'V', u'EH1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'ER0', u'Z')\n",
      "\n",
      "litigate\n",
      "(u'L', u'IH1', u'T', u'IH0', u'G', u'EY2', u'T')\n",
      "\n",
      "irrigators\n",
      "(u'IH1', u'R', u'AH0', u'G', u'EY2', u'T', u'ER0', u'Z')\n",
      "\n",
      "navigator\n",
      "(u'N', u'AE1', u'V', u'AH0', u'G', u'EY2', u'T', u'ER0')\n",
      "\n",
      "northgate\n",
      "(u'N', u'AO1', u'R', u'TH', u'G', u'EY2', u'T')\n",
      "\n",
      "navigating\n",
      "(u'N', u'AE1', u'V', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "relegated\n",
      "(u'R', u'EH1', u'L', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "iraqgate\n",
      "(u'IH0', u'R', u'AA1', u'K', u'G', u'EY2', u'T')\n",
      "\n",
      "arrogate\n",
      "(u'AE1', u'R', u'OW0', u'G', u'EY2', u'T')\n",
      "\n",
      "propagate\n",
      "(u'P', u'R', u'AA1', u'P', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "stargates\n",
      "(u'S', u'T', u'AA1', u'R', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "instigator\n",
      "(u'IH1', u'N', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'ER0')\n",
      "\n",
      "congregated\n",
      "(u'K', u'AA1', u'NG', u'G', u'R', u'IH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "promulgated\n",
      "(u'P', u'R', u'AA1', u'M', u'AH0', u'L', u'G', u'EY2', u'T', u'AH0', u'D')\n",
      "\n",
      "relegate\n",
      "(u'R', u'EH1', u'L', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "mitigate\n",
      "(u'M', u'IH1', u'T', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "propagating\n",
      "(u'P', u'R', u'AA1', u'P', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "stargate\n",
      "(u'S', u'T', u'AA1', u'R', u'G', u'EY2', u'T')\n",
      "\n",
      "litigating\n",
      "(u'L', u'IH1', u'T', u'IH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "travelgate\n",
      "(u'T', u'R', u'AE1', u'V', u'AH0', u'L', u'G', u'EY2', u'T')\n",
      "\n",
      "watergate\n",
      "(u'W', u'AO1', u'T', u'ER0', u'G', u'EY2', u'T')\n",
      "\n",
      "corrugate\n",
      "(u'K', u'AO1', u'R', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "wingate\n",
      "(u'W', u'IH1', u'N', u'G', u'EY2', u'T')\n",
      "\n",
      "applegate\n",
      "(u'AE1', u'P', u'AH0', u'L', u'G', u'EY2', u'T')\n",
      "\n",
      "instigating\n",
      "(u'IH1', u'N', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'IH0', u'NG')\n",
      "\n",
      "subjugate\n",
      "(u'S', u'AH1', u'B', u'JH', u'AH0', u'G', u'EY2', u'T')\n",
      "\n",
      "subjugated\n",
      "(u'S', u'AH1', u'B', u'JH', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "abrogated\n",
      "(u'AE1', u'B', u'R', u'AH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "litigated\n",
      "(u'L', u'IH1', u'T', u'IH0', u'G', u'EY2', u'T', u'IH0', u'D')\n",
      "\n",
      "litigates\n",
      "(u'L', u'IH1', u'T', u'IH0', u'G', u'EY2', u'T', u'S')\n",
      "\n",
      "castigates\n",
      "(u'K', u'AE1', u'S', u'T', u'AH0', u'G', u'EY2', u'T', u'S')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for grapheme,word in pd.grapheme_to_word_dict.iteritems():\n",
    "    graph_chunks = word.grapheme_to_arpabet_phoneme_alignment.seq1\n",
    "    phone_chunks = word.grapheme_to_arpabet_phoneme_alignment.seq2\n",
    "    for k in range(1,6):\n",
    "        for i in range(len(graph_chunks)-k+1):\n",
    "            g = graph_chunks_to_key(graph_chunks[i:i+k])\n",
    "            p = phone_chunks_to_key(phone_chunks[i:i+k])\n",
    "            if g == 'gat' and p == (u'G',u'EY2',u'T'):\n",
    "                print graph_chunks_to_key(graph_chunks)\n",
    "                print phone_chunks_to_key(phone_chunks)\n",
    "                print \n",
    "#             subword_counts[(g,p)] += 1\n",
    "#             if i == 0: # head\n",
    "#                 subgrapheme_head_counts[g] += 1\n",
    "#                 subword_head_counts[(g,p)] += 1\n",
    "#             if i + k == len(graph_chunks): # tail\n",
    "#                 subgrapheme_tail_counts[g] += 1\n",
    "#                 subword_tail_counts[(g,p)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle function objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-467f52ef3542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/test.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jonathansimon/.pyenv/versions/2.7.10/lib/python2.7/copy_reg.pyc\u001b[0m in \u001b[0;36m_reduce_ex\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"can't pickle %s objects\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle function objects"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import dill\n",
    "import cPickle as pkl\n",
    "\n",
    "test_dict = defaultdict(lambda: 1)\n",
    "test_func = lambda: 1\n",
    "with open('../data/test.pkl', 'wb') as outfile:\n",
    "    pkl.dump(test_func, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
